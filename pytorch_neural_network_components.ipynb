{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOL3Qu56JdnX7vAThswzBRe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikravi123/pytorch_practice/blob/main/pytorch_neural_network_components.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Breakdown of a simple neural network\n",
        "\n",
        "x-input  \n",
        "Wx - weights  \n",
        "bx - Bias  \n",
        "A - Activation Function  \n",
        "y - output  \n",
        "\n",
        "z = W1.x + b1\n",
        "to provide non linearity --> Z' =A(z)  \n",
        "Y = W2.Z' + b2\n",
        "\n",
        "#loss function  \n",
        "#calcuate gradient -back propogration\n",
        "# optimizer"
      ],
      "metadata": {
        "id": "fWCJ0vMI8ScA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Components of pytorch\n",
        "\n",
        "- Base class for defining custom model - torch.nn.Module\n",
        "\n",
        "- Fully connected (dense layers): torch.nn.Linear\n",
        "\n",
        "- Activation Function : torch,nn.ReLu\n",
        "- Optimizer: torch.optimizer\n",
        "- loss function:  torch.nn.CrossEntropyLoss\n",
        "- Load data in batch : torch.utils.DataLoader\n"
      ],
      "metadata": {
        "id": "iFDMCwBg9KEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=============================="
      ],
      "metadata": {
        "id": "kpR7O6yF9z08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different way to apply neural networks\n",
        "\n",
        "1. Function: Flexible, harder to interpret\n",
        "2. Sequential : nn.Sequential"
      ],
      "metadata": {
        "id": "l_o6eyWL94Dg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building a Neural Network\n",
        "\n"
      ],
      "metadata": {
        "id": "hp0KbKc_-Ir4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "tWcNSBZw8L2h"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##function API\n",
        "\n",
        "#inherit nn module class\n",
        "class SimpleNN(nn.Module):\n",
        "\n",
        "  def __init__(self,input_size,hidden_size,output_size):\n",
        "    super(SimpleNN,self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(input_size,hidden_size)\n",
        "    self.relu= nn.ReLU()\n",
        "    self.fc2 = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "\n",
        "  ##forward propogation\n",
        "  #x=input size\n",
        "  def forward(self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "H_CZYVds-Ovg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##sequential\n",
        "\n",
        "class SimpleNNSequential(nn.Module):\n",
        "\n",
        "  def __init__(self,input_size,hidden_size,output_size):\n",
        "    super(SimpleNN,self).__init__()\n",
        "\n",
        "    self.network = nn.Sequential(\n",
        "     ##mention flow\n",
        "     ##cant change flow\n",
        "     nn.Linear(input_size,hidden_size),\n",
        "     nn.ReLu(),\n",
        "     nn.Linear(hidden_size,output_size)\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "  ##forward propogation\n",
        "  #x=input size\n",
        "  def forward(self,x):\n",
        "    x = self.network(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "gnptClZTF8xR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training neural network"
      ],
      "metadata": {
        "id": "Y0tIeFvf3nh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_func=SimpleNN(input_size=4,hidden_size=8,output_size=3)\n",
        "print(model_func)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh4KEGC83l1c",
        "outputId": "ef468372-ec78-4dc4-cd83-eddc57222c22"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN(\n",
            "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=8, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X =torch.randn(10,4)  #10 samples ,4 features\n",
        "Y = torch.randint(0,3,(10,))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "##pytorch handles automatically the final output activation function\n",
        "##by default added softmax activation function\n",
        "\n",
        "optimizer = optim.Adam(model_func.parameters(),lr = 0.01)"
      ],
      "metadata": {
        "id": "5gGcKCOc34Tt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGL4LrOW45tV",
        "outputId": "de9712fc-e10a-40a1-f7c5-a6767ee124aa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7527,  2.2602,  1.3192, -0.1213],\n",
              "        [-1.7121, -1.5934, -1.2321, -0.6739],\n",
              "        [ 0.4314, -1.6191,  0.1569, -0.5708],\n",
              "        [-0.5549,  0.3953, -0.6114, -1.7292],\n",
              "        [ 0.8924, -1.6747, -0.5914,  1.4508],\n",
              "        [-0.8610,  1.9103, -1.0333,  1.2010],\n",
              "        [ 1.4551, -0.7426, -1.2137,  0.2655],\n",
              "        [ 0.5841, -0.2292, -0.4832, -0.5050],\n",
              "        [-1.1575, -0.7173,  0.1376,  0.7006],\n",
              "        [ 0.0245, -0.0353, -0.1861, -1.4355]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFtlJZMr46w_",
        "outputId": "dffa0dbb-585c-44c4-cc73-937bcb46b364"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 0, 1, 0, 1, 2, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##training loop\n",
        "\n",
        "epoch = 120\n",
        "\n",
        "for e in range(epoch):\n",
        "  ##clearning gradient before model training\n",
        "  optimizer.zero_grad()\n",
        "  ##clear weight\n",
        "  outputs = model_func(X)\n",
        "  loss = criterion(outputs,Y)\n",
        "  loss.backward()\n",
        "  ##gradient calcuated update gradients\n",
        "  optimizer.step()\n",
        "\n",
        "  if (e+1) % 10 == 0:\n",
        "    print(f\"{e+1}/50,loss {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9YsX3DW47FP",
        "outputId": "527d3360-5a6c-47e9-bd0e-55b754e2d47b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/50,loss 0.3829\n",
            "20/50,loss 0.3272\n",
            "30/50,loss 0.2796\n",
            "40/50,loss 0.2366\n",
            "50/50,loss 0.2001\n",
            "60/50,loss 0.1696\n",
            "70/50,loss 0.1441\n",
            "80/50,loss 0.1236\n",
            "90/50,loss 0.1068\n",
            "100/50,loss 0.0934\n",
            "110/50,loss 0.0820\n",
            "120/50,loss 0.0727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mnxth9dO6Dhf"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}